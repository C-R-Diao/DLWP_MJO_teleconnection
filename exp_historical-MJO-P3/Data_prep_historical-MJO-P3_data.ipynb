{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code to compare mjo teleconnection pattern between DLWPs and ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ds = xr.open_zarr(\n",
    "  'gs://gcp-public-data-arco-era5/ar/full_37-1h-0p25deg-chunk-1.zarr-v3',\n",
    "\n",
    "  chunks=None,\n",
    "  storage_options=dict(token='anon'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Pick MJO phase 3 samples and prepare for validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000-11-17', '2001-01-16', '2001-01-30', '2002-01-19', '2002-11-08', '2002-12-23', '2003-12-01', '2004-01-29', '2006-01-13', '2006-02-27', '2006-12-24', '2007-02-22', '2007-12-13', '2008-02-03', '2008-11-16', '2009-02-25', '2009-11-06', '2009-12-30', '2010-02-18', '2010-11-28', '2011-11-01', '2012-02-29', '2012-11-01', '2012-12-26', '2013-02-14', '2014-02-06', '2015-12-02', '2016-11-24', '2017-02-28', '2017-11-21', '2018-01-01', '2018-02-28', '2018-12-12', '2020-02-29', '2021-01-04', '2022-02-10', '2022-11-07', '2023-01-27']\n"
     ]
    }
   ],
   "source": [
    "#===== MJO phase 3 cases picked from ERA5 =====#\n",
    "fname = './historical-MJO-P3_cases.txt'\n",
    "dates = []\n",
    "\n",
    "# Open the file and read the lines\n",
    "with open(fname, 'r') as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\"#\"):\n",
    "            date = line.strip()\n",
    "            dates.append(date)\n",
    "\n",
    "# Print the list of dates\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-11-17\n",
      "2001-01-16\n",
      "2001-01-30\n",
      "2002-01-19\n",
      "2002-11-08\n",
      "2002-12-23\n",
      "2003-12-01\n",
      "2004-01-29\n",
      "2006-01-13\n",
      "2006-02-27\n",
      "2006-12-24\n",
      "2007-02-22\n",
      "2007-12-13\n",
      "2008-02-03\n",
      "2008-11-16\n",
      "2009-02-25\n",
      "2009-11-06\n",
      "2009-12-30\n",
      "2010-02-18\n",
      "2010-11-28\n",
      "2011-11-01\n",
      "2012-02-29\n",
      "2012-11-01\n",
      "2012-12-26\n",
      "2013-02-14\n",
      "2014-02-06\n",
      "2015-12-02\n",
      "2016-11-24\n",
      "2017-02-28\n",
      "2017-11-21\n",
      "2018-01-01\n",
      "2018-02-28\n",
      "2018-12-12\n",
      "2020-02-29\n",
      "2021-01-04\n",
      "2022-02-10\n",
      "2022-11-07\n",
      "2023-01-27\n"
     ]
    }
   ],
   "source": [
    "#===== create initial data for Pangu from ERA-5=====#\n",
    "fpath = '../data/ERA5/initial_hist-MJO-P3_Pangu/'\n",
    "plev0 = [1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 150, 100, 50] # levels used in Pangu\n",
    "\n",
    "for date in dates:\n",
    "    print(date)\n",
    "\n",
    "    time0 = date + \"T00\"\n",
    "    #========= surface =========#\n",
    "    vname_srf = [\n",
    "        'mean_sea_level_pressure',\n",
    "        '10m_u_component_of_wind',\n",
    "        '10m_v_component_of_wind',\n",
    "        '2m_temperature'\n",
    "    ]\n",
    "\n",
    "    v_srf = ds[vname_srf].sel(time = time0)\n",
    "    v_srf = v_srf.to_array().to_numpy()\n",
    "\n",
    "    fname = fpath + 'input_srf_' + date + '.npy'\n",
    "    np.save(fname, v_srf)\n",
    "    #========= upper ===========#\n",
    "    vname_upper = [\n",
    "        'geopotential',\n",
    "        'specific_humidity',\n",
    "        'temperature',\n",
    "        'u_component_of_wind',\n",
    "        'v_component_of_wind'\n",
    "    ]\n",
    "\n",
    "    v_upper = ds[vname_upper].sel(time = time0, level = plev0)\n",
    "    v_upper = v_upper.to_array().to_numpy()\n",
    "\n",
    "    fname = fpath + 'input_upper_' + date + '.npy'\n",
    "    np.save(fname, v_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== create initial data for NeuralGCM from ERA-5=====#\n",
    "# No need to store that, it is done in NeuralGCM code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-11-17\n",
      "2001-01-16\n",
      "2001-01-30\n",
      "2002-01-19\n",
      "2002-11-08\n",
      "2002-12-23\n",
      "2003-12-01\n",
      "2004-01-29\n",
      "2006-01-13\n",
      "2006-02-27\n",
      "2006-12-24\n",
      "2007-02-22\n",
      "2007-12-13\n",
      "2008-02-03\n",
      "2008-11-16\n",
      "2009-02-25\n",
      "2009-11-06\n",
      "2009-12-30\n",
      "2010-02-18\n",
      "2010-11-28\n",
      "2011-11-01\n",
      "2012-02-29\n",
      "2012-11-01\n",
      "2012-12-26\n",
      "2013-02-14\n",
      "2014-02-06\n",
      "2015-12-02\n",
      "2016-11-24\n",
      "2017-02-28\n",
      "2017-11-21\n",
      "2018-01-01\n",
      "2018-02-28\n",
      "2018-12-12\n",
      "2020-02-29\n",
      "2021-01-04\n",
      "2022-02-10\n",
      "2022-11-07\n",
      "2023-01-27\n"
     ]
    }
   ],
   "source": [
    "#===== create validation data from ERA-5 =====#\n",
    "fpath = './ERA5_subset/validation_hist-MJO-P3/'\n",
    "\n",
    "plev0 = [1000, 925, 850, 700, 600, 500, 400, 300, 250, 200, 150, 100, 50] # levels used in Pangu\n",
    "\n",
    "for date in dates:\n",
    "    # #========= cut 30 days =========#\n",
    "    print(date)\n",
    "    temp = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "    date_range = []\n",
    "    for i in range(31):\n",
    "        date_range.append( (temp+timedelta(days=i)).strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    # Convert back to string\n",
    "    date_range = [date + \"T00\" for date in date_range]\n",
    "\n",
    "    #========= surface =========#\n",
    "    vname_srf = [\n",
    "        'mean_sea_level_pressure',\n",
    "        '10m_u_component_of_wind',\n",
    "        '10m_v_component_of_wind',\n",
    "        '2m_temperature'\n",
    "    ]\n",
    "\n",
    "    v_srf = ds[vname_srf].sel(time = date_range)\n",
    "\n",
    "    fname = fpath + 'era5_srf_' + date + '_30days.nc'\n",
    "    v_srf.to_netcdf(fname)\n",
    "    #========= upper ===========#\n",
    "    vname_upper = [\n",
    "        'geopotential'#,\n",
    "        # 'specific_humidity',\n",
    "        # 'temperature',\n",
    "        # 'u_component_of_wind',\n",
    "        # 'v_component_of_wind'\n",
    "    ]\n",
    "    v_upper = ds[vname_upper].sel(time = date_range, level = plev0)\n",
    "\n",
    "    fname = fpath + 'era5_Z_' + date + '_30days.nc'\n",
    "    v_upper.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== generate ensemble mean data as the intial condition of ens-mean experiment =====#\n",
    "fpath = '../data/ERA5/initial_hist-MJO-P3_Pangu/'\n",
    "\n",
    "files_srf = [os.path.join(fpath, f) for f in os.listdir(fpath) if 'srf' in f and f.endswith('.npy')]\n",
    "files_upper = [os.path.join(fpath, f) for f in os.listdir(fpath) if 'upper' in f and f.endswith('.npy')]\n",
    "\n",
    "def calculate_mean(files):\n",
    "    mean_data = None\n",
    "    count = 0\n",
    "    \n",
    "    for file in files:\n",
    "        data = np.load(file)\n",
    "        if mean_data is None:\n",
    "            mean_data = data\n",
    "        else:\n",
    "            mean_data += data\n",
    "        count += 1\n",
    "    \n",
    "    mean_data /= count\n",
    "    return mean_data\n",
    "\n",
    "mean_srf = calculate_mean(files_srf)\n",
    "mean_upper = calculate_mean(files_upper)\n",
    "\n",
    "np.save(fpath + 'input_srf_ens-mean.npy', mean_srf)\n",
    "np.save(fpath + 'input_upper_ens-mean.npy', mean_upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01', '2018-02-28', '2018-12-12', '2020-02-29', '2021-01-04', '2022-02-10', '2022-11-07', '2023-01-27']\n"
     ]
    }
   ],
   "source": [
    "#===== MJO phase 3 cases picked from ERA5 =====#\n",
    "fname = './historical-MJO-P3_cases_2017beyond.txt'\n",
    "dates = []\n",
    "\n",
    "# Open the file and read the lines\n",
    "with open(fname, 'r') as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\"#\"):\n",
    "            date = line.strip()\n",
    "            dates.append(date)\n",
    "\n",
    "# Print the list of dates\n",
    "print(dates)\n",
    "\n",
    "fpath = '../data/ERA5/initial_hist-MJO-P3_Pangu/'\n",
    "\n",
    "files_upper = [os.path.join(fpath, f) for f in os.listdir(fpath) if 'upper' in f and f.endswith('.npy') and any(date in f for date in dates) ]\n",
    "files_srf = [os.path.join(fpath, f) for f in os.listdir(fpath) if 'srf' in f and f.endswith('.npy')and any(date in f for date in dates) ]\n",
    "\n",
    "def calculate_mean(files):\n",
    "    mean_data = None\n",
    "    count = 0\n",
    "    \n",
    "    for file in files:\n",
    "        data = np.load(file)\n",
    "        if mean_data is None:\n",
    "            mean_data = data\n",
    "        else:\n",
    "            mean_data += data\n",
    "        count += 1\n",
    "    \n",
    "    mean_data /= count\n",
    "    return mean_data\n",
    "\n",
    "mean_srf = calculate_mean(files_srf)\n",
    "mean_upper = calculate_mean(files_upper)\n",
    "\n",
    "np.save(fpath + 'input_srf_ens-mean_2017beyond.npy', mean_srf)\n",
    "np.save(fpath + 'input_upper_ens-mean_2017beyond.npy', mean_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_neuralgcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
